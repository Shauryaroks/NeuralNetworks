{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e5bae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from perceptron import ANN\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c15baf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "# Extract labels and features\n",
    "y = df['label']\n",
    "X = df.drop('label', axis=1)\n",
    "\n",
    "\n",
    "# Normalize pixel values\n",
    "X = X / 255.0\n",
    "\n",
    "\n",
    "y_shuffled = y.copy()\n",
    "X_shuffled = X.copy()\n",
    "\n",
    "# Generate a random permutation of indices\n",
    "permutation = np.random.permutation(len(y))\n",
    "\n",
    "# Shuffle X and y using the same permutation\n",
    "y_shuffled = y_shuffled.iloc[permutation].reset_index(drop=True)\n",
    "X_shuffled = X_shuffled.iloc[permutation].reset_index(drop=True)\n",
    "\n",
    "y_array = y_shuffled.values  # or y_shuffled.to_numpy()\n",
    "X_array = X_shuffled.values  # or X_shuffled.to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_array, y_array, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09f190a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 74345.9371250252\n",
      "Epoch 0, Loss: 74345.9371, Accuracy: 0.1042\n",
      "loss: 67577.64117766403\n",
      "loss: 66620.56393238006\n",
      "loss: 65952.86072830294\n",
      "loss: 65258.860196399\n",
      "loss: 64490.35179667761\n",
      "loss: 63650.36509886179\n",
      "loss: 62758.60784856675\n",
      "loss: 61853.88080429821\n",
      "loss: 60964.72974425166\n",
      "loss: 60086.08534603208\n",
      "Epoch 10, Loss: 60086.0853, Accuracy: 0.3222\n",
      "loss: 59219.7935449826\n",
      "loss: 58364.70735336062\n",
      "loss: 57522.72626881676\n",
      "loss: 56693.21795865731\n",
      "loss: 55872.1048120647\n",
      "loss: 55058.47507220326\n",
      "loss: 54251.232877880124\n",
      "loss: 53448.683232025665\n",
      "loss: 52651.06714637867\n",
      "loss: 51855.606055662836\n",
      "Epoch 20, Loss: 51855.6061, Accuracy: 0.4218\n",
      "loss: 51064.039081773204\n",
      "loss: 50275.831009349284\n",
      "loss: 49487.824048903785\n",
      "loss: 48699.29308670059\n",
      "loss: 47909.4103066253\n",
      "loss: 47117.95552126995\n",
      "loss: 46324.89362667872\n",
      "loss: 45529.40917124436\n",
      "loss: 44730.29776587828\n",
      "loss: 43927.38822835057\n",
      "Epoch 30, Loss: 43927.3882, Accuracy: 0.5333\n",
      "loss: 43121.90903238071\n",
      "loss: 42314.95941486418\n",
      "loss: 41507.58649119355\n",
      "loss: 40698.91220039915\n",
      "loss: 39890.38359783924\n",
      "loss: 39083.62652642494\n",
      "loss: 38277.452406984754\n",
      "loss: 37475.41820296264\n",
      "loss: 36678.103624354095\n",
      "loss: 35886.30959924325\n",
      "Epoch 40, Loss: 35886.3096, Accuracy: 0.6634\n",
      "loss: 35102.522811494215\n",
      "loss: 34327.379343151595\n",
      "loss: 33562.87001637962\n",
      "loss: 32811.40515300484\n",
      "loss: 32074.94688812201\n",
      "loss: 31355.713415438826\n",
      "loss: 30656.2566581052\n",
      "loss: 29978.290236839704\n",
      "loss: 29323.58802808616\n",
      "loss: 28693.87822922436\n",
      "Epoch 50, Loss: 28693.8782, Accuracy: 0.7498\n",
      "loss: 28090.606238157066\n",
      "loss: 27514.95426103966\n",
      "loss: 26967.65050394873\n",
      "loss: 26449.970472788173\n",
      "loss: 25964.079865659034\n",
      "loss: 25514.64891088952\n",
      "loss: 25119.795430726284\n",
      "loss: 24832.435330908396\n",
      "loss: 24780.48700084739\n",
      "loss: 25347.95627315017\n",
      "Epoch 60, Loss: 25347.9563, Accuracy: 0.7630\n",
      "loss: 26985.997805967167\n",
      "loss: 31158.102520377044\n",
      "loss: 32290.383819868563\n",
      "loss: 33729.84388928015\n",
      "loss: 27122.88418118852\n",
      "loss: 24870.201125542244\n",
      "loss: 23295.727038153393\n",
      "loss: 22569.963826625302\n",
      "loss: 22008.17946766666\n",
      "loss: 21631.196558809308\n",
      "Epoch 70, Loss: 21631.1966, Accuracy: 0.7999\n",
      "loss: 21295.62022098038\n",
      "loss: 21023.446259995864\n",
      "loss: 20765.37181884727\n",
      "loss: 20545.001865065755\n",
      "loss: 20330.954016321015\n",
      "loss: 20147.83348122836\n",
      "loss: 19972.357056843735\n",
      "loss: 19831.246745670513\n",
      "loss: 19692.506574791834\n",
      "loss: 19601.313101617307\n",
      "Epoch 80, Loss: 19601.3131, Accuracy: 0.8152\n",
      "loss: 19510.425610722028\n",
      "loss: 19494.288187422077\n",
      "loss: 19461.0485705885\n",
      "loss: 19551.962764584554\n",
      "loss: 19584.685631541735\n",
      "loss: 19818.732625779325\n",
      "loss: 19858.441021102146\n",
      "loss: 20178.622196830824\n",
      "loss: 20078.342949232836\n",
      "loss: 20309.108713329875\n",
      "Epoch 90, Loss: 20309.1087, Accuracy: 0.7869\n",
      "loss: 19933.285556897863\n",
      "loss: 19911.302245352206\n",
      "loss: 19352.424094697555\n",
      "loss: 19130.275043945516\n",
      "loss: 18603.90644577821\n",
      "loss: 18334.002793308795\n",
      "loss: 17937.570433893037\n",
      "loss: 17717.64018951515\n",
      "loss: 17438.607135720187\n",
      "loss: 17263.34379292696\n",
      "Epoch 100, Loss: 17263.3438, Accuracy: 0.8325\n",
      "loss: 17058.160357267843\n",
      "loss: 16916.28458890615\n",
      "loss: 16757.865784009402\n",
      "loss: 16637.25481721196\n",
      "loss: 16509.65888179236\n",
      "loss: 16404.344870162407\n",
      "loss: 16294.142669694114\n",
      "loss: 16201.69049815467\n",
      "loss: 16103.874709041273\n",
      "loss: 16021.038835521778\n",
      "Epoch 110, Loss: 16021.0388, Accuracy: 0.8452\n",
      "loss: 15930.302898756407\n",
      "loss: 15856.880492469492\n",
      "loss: 15774.046023515964\n",
      "loss: 15708.43431455408\n",
      "loss: 15631.726719005095\n",
      "loss: 15578.898771011678\n",
      "loss: 15510.782671510507\n",
      "loss: 15471.165475110913\n",
      "loss: 15410.108272425987\n",
      "loss: 15386.1032319144\n",
      "Epoch 120, Loss: 15386.1032, Accuracy: 0.8491\n",
      "loss: 15332.19053182644\n",
      "loss: 15326.031780061006\n",
      "loss: 15280.950967009583\n",
      "loss: 15294.60656788227\n",
      "loss: 15256.697165893056\n",
      "loss: 15297.153399048682\n",
      "loss: 15257.233675335161\n",
      "loss: 15319.426024501221\n",
      "loss: 15270.753331929534\n",
      "loss: 15346.270859836819\n",
      "Epoch 130, Loss: 15346.2709, Accuracy: 0.8445\n",
      "loss: 15278.864896364896\n",
      "loss: 15353.696165791547\n",
      "loss: 15253.902508763604\n",
      "loss: 15311.224299004865\n",
      "loss: 15168.1750736816\n",
      "loss: 15190.47371733382\n",
      "loss: 15008.918181175435\n",
      "loss: 14990.641176423658\n",
      "loss: 14791.717209472024\n",
      "loss: 14742.836134404708\n",
      "Epoch 140, Loss: 14742.8361, Accuracy: 0.8506\n",
      "loss: 14548.905438508238\n",
      "loss: 14476.052341397306\n",
      "loss: 14303.29464262385\n",
      "loss: 14224.700845002299\n",
      "loss: 14074.488707653501\n",
      "loss: 13993.746385585828\n",
      "loss: 13868.423630265528\n",
      "loss: 13792.056078151432\n",
      "loss: 13688.587967076588\n",
      "loss: 13619.103038314137\n",
      "Epoch 150, Loss: 13619.1030, Accuracy: 0.8674\n",
      "loss: 13531.959706901018\n",
      "loss: 13469.154690242489\n",
      "loss: 13394.856055050035\n",
      "loss: 13337.23595737406\n",
      "loss: 13272.72572768959\n",
      "loss: 13219.324119266184\n",
      "loss: 13161.60383489365\n",
      "loss: 13111.672324374566\n",
      "loss: 13058.916441486039\n",
      "loss: 13012.069299688214\n",
      "Epoch 160, Loss: 13012.0693, Accuracy: 0.8753\n",
      "loss: 12963.866037978956\n",
      "loss: 12918.483820958889\n",
      "loss: 12873.027309846946\n",
      "loss: 12830.283568482293\n",
      "loss: 12786.721059420906\n",
      "loss: 12745.905872691605\n",
      "loss: 12703.916305126422\n",
      "loss: 12664.78457850575\n",
      "loss: 12624.037724367809\n",
      "loss: 12586.048413058119\n",
      "Epoch 170, Loss: 12586.0484, Accuracy: 0.8796\n",
      "loss: 12546.554037388829\n",
      "loss: 12509.6982357618\n",
      "loss: 12470.94592646435\n",
      "loss: 12435.568715583076\n",
      "loss: 12397.884430442231\n",
      "loss: 12363.64999382928\n",
      "loss: 12327.165863554812\n",
      "loss: 12293.246321167559\n",
      "loss: 12257.86352079529\n",
      "loss: 12224.725064299615\n",
      "Epoch 180, Loss: 12224.7251, Accuracy: 0.8824\n",
      "loss: 12189.895616782527\n",
      "loss: 12157.815659988195\n",
      "loss: 12123.853833463065\n",
      "loss: 12092.464778543885\n",
      "loss: 12059.646464390886\n",
      "loss: 12029.067401135544\n",
      "loss: 11996.86532569597\n",
      "loss: 11966.987703599909\n",
      "loss: 11934.911304115221\n",
      "loss: 11905.806583416315\n",
      "Epoch 190, Loss: 11905.8066, Accuracy: 0.8852\n",
      "loss: 11874.21329104193\n",
      "loss: 11845.832958964862\n",
      "loss: 11814.592237358622\n",
      "loss: 11786.876701144265\n",
      "loss: 11756.202918776085\n",
      "loss: 11729.414990109002\n",
      "loss: 11699.209197217202\n",
      "loss: 11673.07159846053\n",
      "loss: 11643.477903451865\n",
      "loss: 11618.12591405127\n",
      "Epoch 200, Loss: 11618.1259, Accuracy: 0.8880\n",
      "loss: 11588.830772074438\n",
      "loss: 11563.66522570659\n",
      "loss: 11534.573558365964\n",
      "loss: 11510.071387856116\n",
      "loss: 11481.712065940032\n",
      "loss: 11457.935263044685\n",
      "loss: 11430.182214117815\n",
      "loss: 11406.737702163324\n",
      "loss: 11379.530392760727\n",
      "loss: 11356.345756771892\n",
      "Epoch 210, Loss: 11356.3458, Accuracy: 0.8906\n",
      "loss: 11329.636020725706\n",
      "loss: 11306.90493007382\n",
      "loss: 11280.865865170876\n",
      "loss: 11258.815895039726\n",
      "loss: 11233.107415399212\n",
      "loss: 11212.102753636213\n",
      "loss: 11186.462450683786\n",
      "loss: 11166.1752591754\n",
      "loss: 11140.438549750252\n",
      "loss: 11120.481094176344\n",
      "Epoch 220, Loss: 11120.4811, Accuracy: 0.8939\n",
      "loss: 11095.219234471158\n",
      "loss: 11076.354524835155\n",
      "loss: 11051.316855167337\n",
      "loss: 11033.080485148857\n",
      "loss: 11008.378849299652\n",
      "loss: 10990.14713286125\n",
      "loss: 10965.274871978956\n",
      "loss: 10947.585407036197\n",
      "loss: 10921.81227853437\n",
      "loss: 10904.561052650635\n",
      "Epoch 230, Loss: 10904.5611, Accuracy: 0.8959\n",
      "loss: 10878.712154885134\n",
      "loss: 10861.65107395314\n",
      "loss: 10836.095081053274\n",
      "loss: 10818.992709275191\n",
      "loss: 10793.34924990643\n",
      "loss: 10776.074303888396\n",
      "loss: 10750.338418133884\n",
      "loss: 10733.021694609051\n",
      "loss: 10707.139736231185\n",
      "loss: 10690.267904656306\n",
      "Epoch 240, Loss: 10690.2679, Accuracy: 0.8980\n",
      "loss: 10664.167693096035\n",
      "loss: 10647.594472738634\n",
      "loss: 10621.690952632873\n",
      "loss: 10604.713317164518\n",
      "loss: 10578.867750735137\n",
      "loss: 10561.849296553037\n",
      "loss: 10536.237288050697\n",
      "loss: 10519.036788878244\n",
      "loss: 10493.57652006003\n",
      "loss: 10476.031931750993\n",
      "Epoch 250, Loss: 10476.0319, Accuracy: 0.8998\n",
      "loss: 10450.456250814383\n",
      "loss: 10432.648039099004\n",
      "loss: 10407.996946758743\n",
      "loss: 10389.9939869396\n",
      "loss: 10365.649722927055\n",
      "loss: 10347.57325867303\n",
      "loss: 10323.679669397407\n",
      "loss: 10305.41881885396\n",
      "loss: 10282.469294052999\n",
      "loss: 10264.467293651875\n",
      "Epoch 260, Loss: 10264.4673, Accuracy: 0.9024\n",
      "loss: 10241.70803578483\n",
      "loss: 10223.51774751522\n",
      "loss: 10201.202872385034\n",
      "loss: 10182.674163737742\n",
      "loss: 10160.858979723287\n",
      "loss: 10142.197985981406\n",
      "loss: 10121.004754847705\n",
      "loss: 10102.895650637747\n",
      "loss: 10082.2186729176\n",
      "loss: 10064.24495592379\n",
      "Epoch 270, Loss: 10064.2450, Accuracy: 0.9039\n",
      "loss: 10043.861187271097\n",
      "loss: 10025.990406884694\n",
      "loss: 10005.858858747617\n",
      "loss: 9988.12332360128\n",
      "loss: 9967.911170182273\n",
      "loss: 9950.47338404063\n",
      "loss: 9930.763304847329\n",
      "loss: 9913.761657090923\n",
      "loss: 9894.38569968604\n",
      "loss: 9877.86084136333\n",
      "Epoch 280, Loss: 9877.8608, Accuracy: 0.9057\n",
      "loss: 9858.8384136407\n",
      "loss: 9842.374086529106\n",
      "loss: 9823.912152550763\n",
      "loss: 9807.715023381075\n",
      "loss: 9789.41741878795\n",
      "loss: 9773.225870822047\n",
      "loss: 9755.37513964621\n",
      "loss: 9739.326767983683\n",
      "loss: 9722.031309382364\n",
      "loss: 9706.275924432519\n",
      "Epoch 290, Loss: 9706.2759, Accuracy: 0.9073\n",
      "loss: 9689.410097959755\n",
      "loss: 9673.805975009964\n",
      "loss: 9657.339082248542\n",
      "loss: 9641.96567718932\n",
      "loss: 9625.86615556089\n",
      "loss: 9610.897295763563\n",
      "loss: 9595.006018925833\n",
      "loss: 9580.164759602925\n",
      "loss: 9564.640866306963\n",
      "loss: 9550.03208130888\n",
      "Epoch 300, Loss: 9550.0321, Accuracy: 0.9086\n",
      "loss: 9534.721210129195\n",
      "loss: 9520.207709013415\n",
      "loss: 9504.964203770622\n",
      "loss: 9490.76276330305\n",
      "loss: 9475.749135828206\n",
      "loss: 9461.8150741447\n",
      "loss: 9446.83213405844\n",
      "loss: 9433.116535132674\n",
      "loss: 9418.344941948675\n",
      "loss: 9404.571912967866\n",
      "Epoch 310, Loss: 9404.5719, Accuracy: 0.9098\n",
      "loss: 9390.014530582634\n",
      "loss: 9376.549957329296\n",
      "loss: 9362.042249685534\n",
      "loss: 9348.68825891622\n",
      "loss: 9334.33218529406\n",
      "loss: 9321.12113461816\n",
      "loss: 9307.032450794422\n",
      "loss: 9294.002256164229\n",
      "loss: 9280.074583425252\n",
      "loss: 9267.01740126526\n",
      "Epoch 320, Loss: 9267.0174, Accuracy: 0.9111\n",
      "loss: 9253.342644651273\n",
      "loss: 9240.412102781738\n",
      "loss: 9226.845011066967\n",
      "loss: 9214.107979111153\n",
      "loss: 9200.732003304398\n",
      "loss: 9188.16234626378\n",
      "loss: 9174.964689015895\n",
      "loss: 9162.414198567843\n",
      "loss: 9149.382080842981\n",
      "loss: 9137.073886323189\n",
      "Epoch 330, Loss: 9137.0739, Accuracy: 0.9122\n",
      "loss: 9124.197728954085\n",
      "loss: 9111.87715077366\n",
      "loss: 9099.217827179622\n",
      "loss: 9087.098901347777\n",
      "loss: 9074.460444465874\n",
      "loss: 9062.41635199494\n",
      "loss: 9049.893717043626\n",
      "loss: 9037.979523185735\n",
      "loss: 9025.565733958\n",
      "loss: 9013.751635512157\n",
      "Epoch 340, Loss: 9013.7516, Accuracy: 0.9131\n",
      "loss: 9001.479021650903\n",
      "loss: 8989.717555452435\n",
      "loss: 8977.655848257193\n",
      "loss: 8966.150499500498\n",
      "loss: 8954.036544424613\n",
      "loss: 8942.552011901555\n",
      "loss: 8930.6233413433\n",
      "loss: 8919.320547573545\n",
      "loss: 8907.521120845917\n",
      "loss: 8896.339200904931\n",
      "Epoch 350, Loss: 8896.3392, Accuracy: 0.9143\n",
      "loss: 8884.695197070567\n",
      "loss: 8873.641161042433\n",
      "loss: 8862.147881648345\n",
      "loss: 8851.199680538575\n",
      "loss: 8839.911078905234\n",
      "loss: 8829.133479786913\n",
      "loss: 8817.911683680362\n",
      "loss: 8807.213864075195\n",
      "loss: 8796.097033666227\n",
      "loss: 8785.45563429597\n",
      "Epoch 360, Loss: 8785.4556, Accuracy: 0.9154\n",
      "loss: 8774.568297511225\n",
      "loss: 8764.03516977173\n",
      "loss: 8753.30592628351\n",
      "loss: 8742.85936360688\n",
      "loss: 8732.209174968964\n",
      "loss: 8721.862456610157\n",
      "loss: 8711.312717028726\n",
      "loss: 8701.127549950867\n",
      "loss: 8690.637712580512\n",
      "loss: 8680.74888812035\n",
      "Epoch 370, Loss: 8680.7489, Accuracy: 0.9167\n",
      "loss: 8670.328191946759\n",
      "loss: 8660.496716299804\n",
      "loss: 8650.249666678192\n",
      "loss: 8640.519008999127\n",
      "loss: 8630.295886468313\n",
      "loss: 8620.667701471764\n",
      "loss: 8610.553185787467\n",
      "loss: 8600.992909881601\n",
      "loss: 8591.041697172595\n",
      "loss: 8581.672242203254\n",
      "Epoch 380, Loss: 8581.6722, Accuracy: 0.9177\n",
      "loss: 8571.979174285523\n",
      "loss: 8562.695294772604\n",
      "loss: 8553.355840734934\n",
      "loss: 8544.187644660764\n",
      "loss: 8534.821473655344\n",
      "loss: 8525.875704492108\n",
      "loss: 8516.805584761501\n",
      "loss: 8508.040351750034\n",
      "loss: 8498.981745741043\n",
      "loss: 8490.354246621115\n",
      "Epoch 390, Loss: 8490.3542, Accuracy: 0.9188\n",
      "loss: 8481.40358886247\n",
      "loss: 8472.961768115845\n",
      "loss: 8464.132246882034\n",
      "loss: 8455.994447505382\n",
      "loss: 8447.473567818462\n",
      "loss: 8439.41335547129\n",
      "loss: 8431.067379743465\n",
      "loss: 8423.328684191607\n",
      "loss: 8415.151466816307\n",
      "loss: 8407.781636592976\n",
      "Epoch 400, Loss: 8407.7816, Accuracy: 0.9196\n",
      "loss: 8399.72354537158\n",
      "loss: 8392.7831006564\n",
      "loss: 8384.884465678579\n",
      "loss: 8378.633057593306\n",
      "loss: 8371.05142981648\n",
      "loss: 8365.317933769475\n",
      "loss: 8358.144102788974\n",
      "loss: 8353.226702344138\n",
      "loss: 8346.310651785589\n",
      "loss: 8341.927464991164\n",
      "Epoch 410, Loss: 8341.9275, Accuracy: 0.9196\n",
      "loss: 8335.371986595233\n",
      "loss: 8331.697410920653\n",
      "loss: 8325.581057777166\n",
      "loss: 8322.682041347161\n",
      "loss: 8316.786370470669\n",
      "loss: 8314.895490606868\n",
      "loss: 8309.128808353751\n",
      "loss: 8307.934082006934\n",
      "loss: 8302.422967060713\n",
      "loss: 8302.407271447246\n",
      "Epoch 420, Loss: 8302.4073, Accuracy: 0.9201\n",
      "loss: 8296.808624052293\n",
      "loss: 8298.21058911029\n",
      "loss: 8292.92509738241\n",
      "loss: 8295.585020223954\n",
      "loss: 8290.353771298378\n",
      "loss: 8294.525112457435\n",
      "loss: 8288.752426108475\n",
      "loss: 8294.54511841014\n",
      "loss: 8288.142772944266\n",
      "loss: 8294.95508337639\n",
      "Epoch 430, Loss: 8294.9551, Accuracy: 0.9197\n",
      "loss: 8288.061320750807\n",
      "loss: 8295.959872299536\n",
      "loss: 8288.376278115456\n",
      "loss: 8297.591791427632\n",
      "loss: 8288.303914760338\n",
      "loss: 8298.353738797981\n",
      "loss: 8287.639642208058\n",
      "loss: 8298.288219488284\n",
      "loss: 8285.599122139269\n",
      "loss: 8295.946735663652\n",
      "Epoch 440, Loss: 8295.9467, Accuracy: 0.9194\n",
      "loss: 8280.122357105429\n",
      "loss: 8288.947479714156\n",
      "loss: 8270.555500091232\n",
      "loss: 8277.390101921344\n",
      "loss: 8256.861759425912\n",
      "loss: 8260.79942826794\n",
      "loss: 8237.822582540635\n",
      "loss: 8239.096992522169\n",
      "loss: 8213.850742390066\n",
      "loss: 8211.616404778997\n",
      "Epoch 450, Loss: 8211.6164, Accuracy: 0.9200\n",
      "loss: 8185.347343702943\n",
      "loss: 8180.665742407567\n",
      "loss: 8153.89726536305\n",
      "loss: 8146.307075640725\n",
      "loss: 8120.093321678658\n",
      "loss: 8110.585754750975\n",
      "loss: 8084.906200083105\n",
      "loss: 8073.820914280021\n",
      "loss: 8049.911517700101\n",
      "loss: 8037.642698637182\n",
      "Epoch 460, Loss: 8037.6427, Accuracy: 0.9219\n",
      "loss: 8015.3130079601815\n",
      "loss: 8002.539989839837\n",
      "loss: 7981.975940161232\n",
      "loss: 7969.139346745272\n",
      "loss: 7950.143295521989\n",
      "loss: 7937.593862654612\n",
      "loss: 7920.577770701146\n",
      "loss: 7908.817373910388\n",
      "loss: 7893.415696671393\n",
      "loss: 7882.133431461468\n",
      "Epoch 470, Loss: 7882.1334, Accuracy: 0.9238\n",
      "loss: 7868.0839865967\n",
      "loss: 7857.3994278872005\n",
      "loss: 7844.4932877674655\n",
      "loss: 7834.406421384934\n",
      "loss: 7822.598368282701\n",
      "loss: 7812.7513416625225\n",
      "loss: 7801.897777342843\n",
      "loss: 7792.551461089229\n",
      "loss: 7782.343914503869\n",
      "loss: 7773.28414607943\n",
      "Epoch 480, Loss: 7773.2841, Accuracy: 0.9250\n",
      "loss: 7763.731248473999\n",
      "loss: 7755.194849686508\n",
      "loss: 7746.110732027948\n",
      "loss: 7737.9830376771115\n",
      "loss: 7729.396213589239\n",
      "loss: 7721.60374122497\n",
      "loss: 7713.428881073608\n",
      "loss: 7705.835183655463\n",
      "loss: 7697.838463202015\n",
      "loss: 7690.34485316387\n",
      "Epoch 490, Loss: 7690.3449, Accuracy: 0.9258\n",
      "loss: 7682.521163817095\n",
      "loss: 7675.11921091823\n",
      "loss: 7667.538009698346\n",
      "loss: 7660.266725351072\n",
      "loss: 7652.831651050635\n",
      "loss: 7645.665495727879\n",
      "loss: 7638.363374804385\n",
      "loss: 7631.340438745227\n",
      "loss: 7624.232184825658\n",
      "loss: 7617.223335036919\n",
      "Epoch 500, Loss: 7617.2233, Accuracy: 0.9264\n",
      "loss: 7610.175848990912\n",
      "loss: 7603.210100416971\n",
      "loss: 7596.348947919807\n",
      "loss: 7589.636957326191\n",
      "loss: 7582.7690678475465\n",
      "loss: 7576.133398841589\n",
      "loss: 7569.304322066412\n",
      "loss: 7562.760085136339\n",
      "loss: 7556.090270272494\n",
      "loss: 7549.562036860353\n",
      "Epoch 510, Loss: 7549.5620, Accuracy: 0.9274\n",
      "loss: 7542.958285706426\n",
      "loss: 7536.4268244088935\n",
      "loss: 7529.885966704796\n",
      "loss: 7523.322969503179\n",
      "loss: 7516.820271152728\n",
      "loss: 7510.392840425243\n",
      "loss: 7503.980421884937\n",
      "loss: 7497.54591080758\n",
      "loss: 7491.201615967504\n",
      "loss: 7484.7894157715855\n",
      "Epoch 520, Loss: 7484.7894, Accuracy: 0.9280\n",
      "loss: 7478.447525535732\n",
      "loss: 7472.127725544445\n",
      "loss: 7465.833802493179\n",
      "loss: 7459.582247920491\n",
      "loss: 7453.31971640208\n",
      "loss: 7447.100330793192\n",
      "loss: 7440.903339828275\n",
      "loss: 7434.77392159849\n",
      "loss: 7428.6307201127665\n",
      "loss: 7422.564136385445\n",
      "Epoch 530, Loss: 7422.5641, Accuracy: 0.9285\n",
      "loss: 7416.508456059719\n",
      "loss: 7410.4631741544545\n",
      "loss: 7404.447847923691\n",
      "loss: 7398.458134713797\n",
      "loss: 7392.429209663853\n",
      "loss: 7386.506438819872\n",
      "loss: 7380.49392732053\n",
      "loss: 7374.6083163448475\n",
      "loss: 7368.625830615068\n",
      "loss: 7362.753501690027\n",
      "Epoch 540, Loss: 7362.7535, Accuracy: 0.9291\n",
      "loss: 7356.869320932727\n",
      "loss: 7351.073926778573\n",
      "loss: 7345.267742740016\n",
      "loss: 7339.570251141491\n",
      "loss: 7333.846828447867\n",
      "loss: 7328.144225640063\n",
      "loss: 7322.403188096154\n",
      "loss: 7316.7092909962885\n",
      "loss: 7311.061559811637\n",
      "loss: 7305.401579682263\n",
      "Epoch 550, Loss: 7305.4016, Accuracy: 0.9293\n",
      "loss: 7299.808738649662\n",
      "loss: 7294.216082174175\n",
      "loss: 7288.674774300312\n",
      "loss: 7283.279075636554\n",
      "loss: 7277.739259738895\n",
      "loss: 7272.431447661632\n",
      "loss: 7266.964455729045\n",
      "loss: 7261.759506937028\n",
      "loss: 7256.379868277911\n",
      "loss: 7251.349869422959\n",
      "Epoch 560, Loss: 7251.3499, Accuracy: 0.9296\n",
      "loss: 7245.943510464656\n",
      "loss: 7240.938202309648\n",
      "loss: 7235.608893997729\n",
      "loss: 7230.713553224074\n",
      "loss: 7225.505641120076\n",
      "loss: 7220.642544861168\n",
      "loss: 7215.5661090713165\n",
      "loss: 7210.897172302166\n",
      "loss: 7205.949424204134\n",
      "loss: 7201.438677757916\n",
      "Epoch 570, Loss: 7201.4387, Accuracy: 0.9301\n",
      "loss: 7196.679160806998\n",
      "loss: 7192.477154723688\n",
      "loss: 7187.94803527763\n",
      "loss: 7184.083836615724\n",
      "loss: 7179.653973994993\n",
      "loss: 7176.032396032016\n",
      "loss: 7171.581600037143\n",
      "loss: 7168.234531782186\n",
      "loss: 7164.019602969327\n",
      "loss: 7161.154074302837\n",
      "Epoch 580, Loss: 7161.1541, Accuracy: 0.9305\n",
      "loss: 7157.262088094347\n",
      "loss: 7154.906364991151\n",
      "loss: 7151.305450890474\n",
      "loss: 7149.551495622876\n",
      "loss: 7146.172112096643\n",
      "loss: 7145.173446890252\n",
      "loss: 7142.182190181204\n",
      "loss: 7142.057181480104\n",
      "loss: 7139.278417958613\n",
      "loss: 7140.055755067246\n",
      "Epoch 590, Loss: 7140.0558, Accuracy: 0.9311\n",
      "loss: 7137.692803302823\n",
      "loss: 7139.782613107288\n",
      "loss: 7137.840072483942\n",
      "loss: 7141.078568684248\n",
      "loss: 7139.841693240203\n",
      "loss: 7145.033346510965\n",
      "loss: 7144.592198915933\n",
      "loss: 7152.2230928001145\n",
      "loss: 7152.269370379097\n",
      "loss: 7162.457920245282\n",
      "Epoch 600, Loss: 7162.4579, Accuracy: 0.9304\n",
      "loss: 7162.9019478101145\n",
      "loss: 7176.342456657174\n",
      "loss: 7177.38201040591\n",
      "loss: 7194.162076389597\n",
      "loss: 7195.284469813613\n",
      "loss: 7215.8099208334825\n",
      "loss: 7217.113561638104\n",
      "loss: 7242.640948194381\n",
      "loss: 7242.86873155358\n",
      "loss: 7272.863142346707\n",
      "Epoch 610, Loss: 7272.8631, Accuracy: 0.9292\n",
      "loss: 7272.61480473007\n",
      "loss: 7308.787360475206\n",
      "loss: 7307.443241068631\n",
      "loss: 7349.673500928782\n",
      "loss: 7345.567675147393\n",
      "loss: 7394.425451849293\n",
      "loss: 7385.427337557416\n",
      "loss: 7437.449749852898\n",
      "loss: 7420.33830996648\n",
      "loss: 7472.206559846514\n",
      "Epoch 620, Loss: 7472.2066, Accuracy: 0.9265\n",
      "loss: 7446.3469093367985\n",
      "loss: 7493.939885925736\n",
      "loss: 7457.036781793743\n",
      "loss: 7496.42621772086\n",
      "loss: 7445.607434221569\n",
      "loss: 7469.70780199616\n",
      "loss: 7405.403308004272\n",
      "loss: 7409.99138633098\n",
      "loss: 7336.287389070507\n",
      "loss: 7323.524825825317\n",
      "Epoch 630, Loss: 7323.5248, Accuracy: 0.9281\n",
      "loss: 7248.140041316769\n",
      "loss: 7222.48691076684\n",
      "loss: 7152.165652009869\n",
      "loss: 7122.047223697611\n",
      "loss: 7063.693095081504\n",
      "loss: 7035.190576333058\n",
      "loss: 6990.450170769789\n",
      "loss: 6966.342841234756\n",
      "loss: 6934.073867173198\n",
      "loss: 6914.838604929968\n",
      "Epoch 640, Loss: 6914.8386, Accuracy: 0.9331\n",
      "loss: 6891.594346911951\n",
      "loss: 6876.331937929461\n",
      "loss: 6859.603411315769\n",
      "loss: 6847.571825513842\n",
      "loss: 6834.792181344734\n",
      "loss: 6825.146697633357\n",
      "loss: 6815.059640572137\n",
      "loss: 6806.942393666153\n",
      "loss: 6798.597274304038\n",
      "loss: 6791.479594561956\n",
      "Epoch 650, Loss: 6791.4796, Accuracy: 0.9339\n",
      "loss: 6784.472136873195\n",
      "loss: 6778.028055917137\n",
      "loss: 6771.710498000294\n",
      "loss: 6765.877035247087\n",
      "loss: 6760.00636531133\n",
      "loss: 6754.5431146295505\n",
      "loss: 6749.000823919333\n",
      "loss: 6743.718825677481\n",
      "loss: 6738.457157908289\n",
      "loss: 6733.378776987631\n",
      "Epoch 660, Loss: 6733.3788, Accuracy: 0.9354\n",
      "loss: 6728.303952205493\n",
      "loss: 6723.336276853224\n",
      "loss: 6718.362709351126\n",
      "loss: 6713.509688997274\n",
      "loss: 6708.645826606858\n",
      "loss: 6703.851586207367\n",
      "loss: 6699.075911454944\n",
      "loss: 6694.352620380245\n",
      "loss: 6689.640519442392\n",
      "loss: 6684.985021546874\n",
      "Epoch 670, Loss: 6684.9850, Accuracy: 0.9358\n",
      "loss: 6680.328477844787\n",
      "loss: 6675.713000701406\n",
      "loss: 6671.135979604756\n",
      "loss: 6666.567469458397\n",
      "loss: 6662.020243993278\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create model\n",
    "model = ANN(y_train, X_train, seed=102)\n",
    "\n",
    "# Train the model\n",
    "model.train(epochs=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ac489d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Predictions: 11752\n",
      "Total Samples: 12600\n",
      "Test Accuracy: 0.9326984126984127\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Manual prediction function (same as your model's internal logic)\n",
    "def predict(model, X):\n",
    "    A = X\n",
    "    for i in range(model.layers - 1):\n",
    "        Z = np.dot(A, model.weights[f\"w{i}\"]) + model.bias[f\"b{i}\"]\n",
    "        if i < model.layers - 2:\n",
    "            A = model.activate(Z)\n",
    "        else:\n",
    "            A = model.softmax(Z)\n",
    "    return np.argmax(A, axis=1)\n",
    "\n",
    "# Get predictions on test set\n",
    "y_pred = predict(model, X_test)\n",
    "\n",
    "# Calculate accuracy manually\n",
    "correct = np.sum(y_pred == y_test)\n",
    "total = len(y_test)\n",
    "accuracy = correct / total\n",
    "\n",
    "print(\"Correct Predictions:\", correct)\n",
    "print(\"Total Samples:\", total)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b95d73d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
